\chapter{URM computability}

\section {Which model?}

To give a formal notion of computability we must choose a concrete model of computation that induces a class of algorithms and therefore of computable functions. 
Despite the fact that we focus on an abstract ideal model, there are still a lot of possibilities. Many models have been considered in the literature:

\begin{enumerate}
\item Turing machine (Turing, 1936)
\item $\lambda$-calculus (Church, 1930)
\item Partial recursive functions (Godel-Kleene 1930)
\item Canonical deductive systems (Post, 1943)
\item Markov systems (Markov, 1951)
\item Unlimited register machine (URM) (Shepherdson - Sturgis, 1963)
\end{enumerate}

In principle, each computational model determines a class of computable functions.
We may be concerned thinking that the developed theory is valid only for a specific
model chosen. In fact, it can be verified that the class of computable functions for all
models cited (for all the models ``sufficiently expressive'' considered
in literature) is always the same. This leads to the so-called Church-Turing
thesis:

\textbf{Church-Turing thesis}: A function is computable by an
effective procedure (i.e., in a finitary computational model, obeying the conditions (a)-(e) from the chapter before) if and only if it is computable
by a Turing machine.


This means that the notion of ``computable function'' is robust (i.e. independent of the specific computational model), and we can choose our favorite one for developing our theory.

\begin{remark}
  The \emph{Church-Turing thesis} is called a thesis and not a theorem due
  of its informal nature. 
  It cannot be proved w.r.t effective procedures, but is supported only by evidence: 
  several computational models have been considered and all respect the thesis 
  (e.g. Yuri Gurevich, argues that it should be proved on the basis of a formal
  axiomatization of conditions (a) - (e)).
\end{remark}

Sometimes we resort to the Church-Turing thesis to shorten the proof that a certain entity is computable, however it can only be used when it is not strictly necessary, i.e. when it could be replaced by a formal proof
(and providing all the details could hide the intuitive idea under a bunch of technicalities).

\section{URM (Unlimited register machine)}

We will formalise the notion of \textbf{computable function} by using an \textbf{abstract machine} 
called \textbf{URM-machine} (Unlimited Register Machine), 
which is an abstraction of a computer based on the Von Neumann's model. It is characterized by

\begin{itemize}
\item \textbf{unbounded memory} that consists of a infinite sequence of \textbf{registers}, each of which can store a  natural number


  $\begin{tabu}{|c|c|c|c|c|}
    \hline
    R_1 & R_2 & \dots & R_n & \dots \\
    \hline
    r_1 & r_2 & \dots & r_n & \dots \\
    \hline
  \end{tabu}$

  the $n$-th register is indicated with $R_n$, its content with $r_n$

  the sequence $(r_1, r_2,\dots, r_n,\dots) \in \nat^\omega$ is called
  \textbf{configuration} of the URM;

\item a \textbf{computing agent} capable of executing an URM program;

\item  a \textbf{URM program}, i.e. a finite sequence of instructions
  $I_1, I_2, \dots, I_s$ that can ``locally'' alter the configuration
  of the URM.
\end{itemize}


Program instructions can be the following

\begin{itemize}

\item \textbf{zero} $Z(n)$ sets the content of the register $R_n$ to zero: $r_n \leftarrow 0$;

\item \textbf{successor} $S(n)$ increments the content of the $R_n$ register by 1: $r_n \leftarrow r_n+1$;

\item \textbf{transfer} $T(m,n)$ transfers the content of the register $R_m$ in the register $R_n$, $R_m$ stays untouched: $r_n\leftarrow r_m$.
\end{itemize}
The above are often referred to as \emph{arithmetic instructions}. They are characterised by the fact that the instruction to be executed in the next step
 is the one following the current instruction in the program.

Then last instruction  is 
\begin{itemize}
\item \textbf{conditional jump} $J(m,n,t)$ compares the content of the registers $R_m$ and $R_n$
  \begin{itemize}
  \item if $r_m = r_n$ it jumps to the $t$-th instruction;
  \item otherwise, it continues with the next instruction.
  \end{itemize}
\end{itemize}


\begin{example}
  An example of program is the following:
  \begin{quote}
    \begin{tabular}{llr}
      $I_1$: & J(2,3,5) &                       \\
      $I_2$: & S(1)     &                       \\
      $I_3$: & S(3)     &                       \\
      $I_4$: & J(1,1,1) &  \comment{unconditional jump}
    \end{tabular}
  \end{quote}

  Disregard what this program computes for the moment. The computation starting from the configuration below is:

  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      1   & 2   & 0   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_1, I_2}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      2   & 2   & 0   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_3}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      2   & 2   & 1   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_4, I_1, I_2}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      3   & 2   & 1   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_3}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      3   & 2   & 2   & \dots \\
      \hline
    \end{tabu}
    \xrightarrow{I_4, I_1, I_5}
    $
  \end{center}
\end{example}


The \textbf{state} of the URM machine in which it executes a program $P = I_1 \dots I_s$ 
is given by a pair $\langle c, t \rangle$ that consists of a

\begin{itemize}
\item \emph{register configuration} $c$\\
  a total function $c : \nat \to \nat$ such that $c(n)$ is the content
  of register $R_n$;

\item \emph{program counter} $t$, i.e., index of the current instruction.
\end{itemize}

An \emph{operational semantics} can easily be defined via a set of deduction rules 
axiomatising the state transitions  $\langle c, t \rangle \rightarrow \langle c', t' \rangle$. 
However we do not need this level of formality, and we will rely on an informal description of the program execution.


\begin{remark}
  A computation might \textbf{not terminate}! Consider for instance the program

  \begin{quote}
    \begin{tabular}{ll}
      $I_1$: & S(1)     \\
      $I_2$: & J(1,1,1)
    \end{tabular}
  \end{quote}

  Then the computation will not terminate. For instance
  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      0  & 0   & 0   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_1, I_2}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      1   & 0   & 0   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{I_1, I_2}
    %
    \begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      2   & 0  & 0   & \dots \\
      \hline
    \end{tabu}
    %
    \xrightarrow{\ldots}
    %
    $
  \end{center}
\end{remark}


\begin{notation}
  Let $P$ be an URM program, and $(a_1,a_2,a_3,\dots) \in \nat^\omega$ a sequence
  of natural numbers. We indicate the computation of $P$ starting from the
  initial configuration by $P(a_1,a_2,\dots)$:

  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      a_1 & a_2 & a_3 & \dots \\
      \hline
    \end{tabu}$
  \end{center}

  and

  \begin{itemize}
  \item $P(a_1,a_2,\dots) \downarrow$ if the computation \textbf{halts}.
  \item $P(a_1,a_2,\dots) \uparrow$ if the computation \textbf{never
      halts} (i.e., it \textbf{diverges}).
  \end{itemize}


  We will work on computations that start from an initial configuration
  where only a \textbf{finite number of registers contain a non-zero value} for
  the majority of the time (almost always for obvious reasons of input
  finiteness). Hence; given $a_1,a_2,\dots,a_k \in \nat$ we will write

  \begin{center}
    $P(a_1,\dots,a_k)$ for 
    $P(a_1,\dots,a_k,0,\dots,0)$
  \end{center}

  The notation extends to $P(a_1,\dots,a_k)\downarrow$ or
  $P(a_1,\dots,a_k)\uparrow$.
\end{notation}

\section{URM-computable functions}

Let $f : \nat^k \rightarrow \nat$ be a partial function. What does it mean for  $f$ to be computable by an URM machine?

Intuitively, it means that there exists a program $P$ such that for each $(a_1,\dots,a_k) \in \nat^k$, 
$P(a_1,\dots,a_k)$ computes the value of $f$, i.e. when $(a_1,\dots,a_k) \in \dom{f}$, 
$P$ terminates and outputs $f(a_1, \ldots, a_k)$. 
However, $P$ does not terminate if $(a_1,\dots,a_k) \not\in \dom{f}$.

A doubt could be about where the output is stored. 
We conventionally decide that the output will be in the first register $R_1 $(at the end of the computation, any register other than the first register contains irrelevant data). 
For this reason we introduce the following notation

\begin{notation}
  Let $P$ be a program and $(a_1,\dots,a_k) \in \nat^k$, we write
  $P(a_1,\dots,a_k)\downarrow a$ if $P(a_1,\dots,a_k) \downarrow$ and
  the final configuration contains $a$ in $R_1$
\end{notation}

\begin{definition}[URM-computable function]
  A function $f:\nat^k\rightarrow\nat$ is said to be
  \textbf{URM-computable} if there exists a URM program $P$ such that for all
  $(a_1,\dots,a_k) \in \nat^k$ and $a\in\nat$,
  $P(a_1,\dots,a_k)\downarrow$ if and only if $(a_1,\dots,a_k)\in dom(f)$ and
  $f(a_1,\dots,a_k) = a$. 
  
  In this case we say that $P$ computes $f$.

  We denote by $\mathcal{C}$ the class of all URM-computable
  functions and by $\mathcal{C}^{(k)}$ the class of the k-ary
  URM-computable functions.
  Therefore we have
  $\mathcal{C} = \bigcup_{k\geq 1} \mathcal{C}^{(k)}$
\end{definition}

\section{Examples of URM-computable functions}

We next list some URM-computable functions, providing the corresponding programs.

\begin{enumerate}
\item $f:\nat^2 \rightarrow \nat$\\
  $f(x,y) = x+y$

  \begin{quote}
    \begin{tabular}{lll}
      $I_1$: & J(2,3,5) &                    \\
      $I_2$: & S(1)     &                    \\
      $I_3$: & S(3)     &                    \\
      $I_4$: & J(1,1,1) &  \comment{unconditional jump}
    \end{tabular}
  \end{quote}

  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      x   & y   & 0   & \dots \\
      \hline
    \end{tabu}$
  \end{center}

  \emph{Idea}: Increment $R_1$ and $R_3$ until $R_2$ and $R_3$ contain
  the same value. This results in adding to $R_1$ the content of
  $R_2$.

\item $f:\nat \rightarrow \nat$\\
  $f(x) = x\dot{-}1 = \begin{cases} 0 & x=0 \\ x-1 & x>0 \end{cases}$

  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      x   & 0   & 0   & \dots \\
      \hline
    \end{tabu}$
  \end{center}

  \emph{Idea}: if $x=0$ it trivially terminates; if $x>0$ keep a value $k-1$ in
  $R_2$ and $k$ in $R_5$, with $k>1$ ascending until $R_3=x$, at that
  point $R_2 = x-1$.

  Here's the program

  \begin{quote}
    \begin{tabular}{lll}
      $I_1$: & J(1,3,8) \\
      $I_2$: & S(3)     \\
      $I_3$: & J(1,3,7) \\
      $I_4$: & S(2)     \\
      $I_5$: & S(3)     \\
      $I_6$: & J(1,1,3) \\
      $I_7$: & T(2,1)   \\
    \end{tabular}
  \end{quote}


\item $f:\nat \rightarrow \nat$\\
  $f(x) = \begin{cases}
    \dfrac{x}{2} & \mbox{if $x$ even}\\
    \uparrow      & \mbox{otherwise}
  \end{cases}$

  \emph{Idea:} Store and increasing even number in $R_2$ and store its' half in
  $R_3$.
  \begin{center}
    $\begin{tabu}{|c|c|c|c|}
      \hline
      R_1 & R_2 & R_3 & \dots \\
      \hline
      x   &  2k  & k   & \dots \\
      \hline
    \end{tabu}$
  \end{center}

  \begin{quote}
    \begin{tabular}{lll}
      $I_1$: & J(1,2,6) \\
      $I_2$: & S(2)     \\
      $I_3$: & S(2)     \\
      $I_4$: & S(3)     \\
      $I_5$: & J(1,1,1) \\
      $I_6$: & T(3,1)   \\
    \end{tabular}
  \end{quote}

\end{enumerate}

\section {Function computed by a program}
Given a program $P$, for some fixed number $k \geq 1$ of parameters, there exists a unique \textbf{function computed by $P$} that we denote by $f_P^{(k)} : \nat^k \to \nat$ defined by:

\begin{equation*}
  f_P^{(k)}(a_1, \dots, a_k) = \begin{cases}
    a        & $ if $ P(a_1, \dots, a_k) \downarrow a  \quad \\
    \uparrow & $ if $ P(a_1, \dots, a_k) \uparrow
  \end{cases}
\end{equation*}

\begin{remark}
  The same function can be computed by different programs, for the following two reasons

  \begin{itemize}
  \item we can add useless instructions to a program (dead code, $T(n,n)$, ...)

  \item the same function can be computed via different algorithms
    (e.g., for sorting we have quicksort, mergesort, heapsort, etc.)
  \end{itemize}

  A function can be computed either by no program or by infinitely many programs.
\end{remark}

\section{Exercises}

\begin{exercise}[Reduced URM]
Consider the URM machine without transfer instruction. We indicate the class
of functions that can be computed with the reduced machine $\mathcal{C}^- $ and
we compare it with $\mathcal{C} $. Obviously $\mathcal{C}^- \subseteq \mathcal{C}
$. Let us see if $\mathcal{C} \subseteq \mathcal{C}^-$. 
\begin{proof}
Informally an instruction $T(m,n)$ at the $t$ step
can be replaced with the following subroutine
\begin{quote}
  \begin{tabular}{lll}
    $I_{t'}$:   & $J(1,1,t'+5)$  \\
    $I_{t'+1}$: & $Z(n)$        \\
    $I_{t'+2}$: & $J(m,n,t+1)$  \\
    $I_{t'+3}$: & $S(n)$        \\
    $I_{t'+4}$: & $J(1,1,t'+2)$ \\
  \end{tabular}
\end{quote}
where $t'>l(P)$.

We prove it formally. 
Given $f \in \mathcal{C} $, $f: \nat^k \rightarrow \nat $, there is an URM program $P$ such that $f_P^{(K)}  = f$. The program $P$ can be transformed into $P ^R $ of the reduced URM machine such that $f_{P^R}^{(K)}  = f_{P}^{(K)}$.

There is a proof by induction. We show that $P$ can be transformed into $P' $ s.t. $ f_{P'}^{(K)}  = f_{P}^{(K)} $ by induction on $h$, number of transfer instructions $T$ in $P$.

\begin{enumerate}
  \item $h = 0$ trivial.
  \item $h \rightarrow  h + 1$: $P$ contains $h + 1$ transfer instructions.
  Transform $P$ into $P''$ where all instructions from $1$ to $l(P)$ are as same as before, while instead of $T$ we put a jump $J(1,1, SUB)$ where the subroutine is written before. 
  We assume that if $P$ ends, it does so at instruction $l(P) + 1$, then at position $l(P) + 1$ we insert $J (1,1, END)$. 
  After these replacements, we have $h$ instructions $T$ and therefore we can say that we have a reduced URM program such that the computed function is the same by inductive assumption.
\end{enumerate}
\end{proof}
\end{exercise}

\begin{exercise}[URM with swap instruction]
  Let $URM^S $ be the model obtained by removing the transfer
  instruction and inserting a swap instruction $ T_S(m,n) $,
  exchanging the contents of registers $m$ and $n$, and let $\mathcal{C}^S$ be the corresponding class of computable functions.. How do the classes $\mathcal{C}$ and $\mathcal{C}^S$ relate?
\begin{proof}
\begin{itemize}
  \item[($\mathcal{C} \subseteq \mathcal{C}^S$)]
  We already know that $\mathcal{C} \subseteq \mathcal{C}^R $ by the previous exercise and therefore, since $\mathcal{C}^R \subseteq \mathcal{C}^S$, the desired inclusion follows by transitivity.
  
  \item[($\mathcal{C}^S \subseteq \mathcal{C}$)]
  We first prove that the swap instruction $T_S (m, n)$ is equivalent to the program below, where $i$ is a ``new'' register:
  \begin{quote}
    \begin{tabular}{l}
    $T(n,i)$ \\
    $T(m,n)$ \\
    $T(i,m)$
    \end{tabular}
    \end{quote}

More formally, let $ f \in \mathcal{C}^S$, $f:\nat\rightarrow \nat $. There exists $P$
$URM^S $ s.t. $ f_P^{(K)} = f $. Let us proceed by induction on the
number of swap instructions $h$.
\begin{enumerate}
  \item[($h = 0$)] the program is already a URM program. therefore $P' = P$.
  \item[($h \rightarrow h+1$)] Assume that $P$ includes $h+1$ swap instructions. 

  Let $i$ be a register not used by $P$ (observe that it can be found by just inspecting the program). Let $t$ be the index of a swap instructions.
  We replace such instruction by a jump
  \begin{quote}
    $I_t : J (1,1, SUB)$
  \end{quote}
  to a subroutine encoding the swap. At the end of the subroutine we return to the starting point with $J (1,1, t + 1)$. Let $P''$ be the program obtained in this way. Since it has only $h$ swap instructions, by inductive hypothesis there is $P'$ URM such that $ f_{P'}^{(K)} = f_{P''}^{(K)} = f_{P}^{(K)}$.
  
  \textbf{But all of this is wrong!}
  
  Why is it wrong? Because the program $P''$ obtained from $P$ replacing a swap instruction will indeed have $n-1$ swap instructions but also some transfer instructions, hence it is not a $URM^S$ program.
  
  We can overcome the problem by proving the following stronger
  statement: given a program $P$ that uses both URM instructions and
  $URM^S$ instructions, there is a program $P'$ that uses $URM$
  instructions only such that $ f_{P}^{(K)} = f_{P'}^{(K)} $.
  
  The proof procedure is the same but, since we are proving a stronger
  statement, the inductive case now works smoothly. This proves that
  $ \mathcal{C}^S \subseteq \mathcal{C} $.
\end{enumerate}
\end{itemize}



Therefore we deduce $\mathcal{C}^S = \mathcal{C}$, as desired.
\end{proof}

\end{exercise}

\begin{exercise}[URM without jump instructions]
Consider an URM machine without jump instructions  $J(m,n,t)$ and call it URM$ ^{nj}$. Let $\mathcal{C}^{nj}$ be the corresponding class of computable functions. How does this class relate to $\mathcal{C}$?


\begin{proof}

  Clearly $\mathcal{C}^{nj} \subseteq \mathcal{C}$ and the inclusion is strict since,  $f: \nat \rightarrow \nat$ with $f(x)\uparrow \forall x$ is computable in URM, but it is not computable in URM $ ^{nj} $.  In fact, all functions in $\mathcal{C}^{nj}$  are total since programs without jump instructions always terminate.

  We can characterise precisely the (unary) functions in $\mathcal{C}^{nj}$. They are of the shape:
\begin{itemize}
  \item $f(x) = c$
  \item $ f(x) = x + c$
\end{itemize}
where $c$ is a constant in $\nat$.

This can be proved as follows. Denote by $r_1(h,x) $ the content of register $R_1$ after $h$ steps starting from an initial configuration where $R_1$ is $x$ and the other registers contain $0$.

We show by induction on $h$ that after $h$ execution steps $r_1(h,x) $ is equal to $x + c$ or to $c$.

\begin{itemize}
  \item Case $h = 0: r_1(0,x) = x $

  \item Case $h \rightarrow h+1$: We know $ r_1(h,x) = x+c $ or $ c $ by inductive hypothesis. The next instruction can be of three shapes:
  \begin{itemize}
  \item The instruction is $Z (n)$. If $n = 1$, $r_1(h+1,x) = 0 $, otherwise $r_1(h+1,x) = r_1(h,x)$, and we conclude by induction hypothesis.
    
  \item The instruction is $S (n)$. If $n = 1$ we have that $r_1(h+1,x) = r_1(h,x)+1 $ which, by induction hypothesis, is fine. Otherwise,  $r_1(h+1,x) = r_1(h,x)$ and we conclude by induction hypothesis.
    
  \item The instruction is $T (m, n)$. When $n>1 $ or $n=m=1$ then $r_1(h+1,x) = r_1(h,x)$ and we conclude by inductive hypothesis. Otherwise, if $n = 1,\ m > 1$ we do know nothing about the content of $r_1(h+1,x) $. We are stuck ...knows?
  \end{itemize}

  \medskip The problem can be solved by observing that register $1$
  has nothing special and the same result can be proved for all
  registers. More precisely, denote by Denote by $r_n(h,x)$ the
  content of register $R_n$ after $h$ steps starting from an initial
  configuration where $R_1$ is $x$ and the other registers contain
  $0$. Then one can show that $r_n(h,x)$ contains either $c$ or $x+c$
  for a suitable constant $c$. In this case the proof goes smoothly.
\end{itemize}
\end{proof}
\end{exercise}
